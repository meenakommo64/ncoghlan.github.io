<!DOCTYPE html><html lang="en">
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta charset="utf-8">
    <meta name="description" content="Efficiency (a virtue) is the child of laziness and greed (both vices), while
much of our economic activity is devoted to preventing boredom in the idle
time created by increases in efficiency. To be human is to be a strange
creature indeed :)
">
    <meta name="author" content="Nick Coghlan">
    <title>Curious Efficiency (old posts page 1) | Curious Efficiency</title>
    
            <link href="assets/css/bootstrap.min.css" rel="stylesheet" type="text/css">
            <link href="assets/css/bootstrap-responsive.min.css" rel="stylesheet" type="text/css">
        <link href="assets/css/rst.css" rel="stylesheet" type="text/css">
        <link href="assets/css/code.css" rel="stylesheet" type="text/css">
        <link href="assets/css/colorbox.css" rel="stylesheet" type="text/css">
        <link href="assets/css/theme.css" rel="stylesheet" type="text/css">
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js" type="text/javascript"></script>
    <![endif]-->
            <link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">

    
    
    
</head>
<body>
<!-- Menubar -->
<div class="navbar navbar-fixed-top">
    <div class="navbar-inner">
        <div class="container">

        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
        </a>

            <a class="brand" href=".">
            Curious Efficiency
            </a>
            <!-- Everything you want hidden at 940px or less, place within here -->
            <div class="nav-collapse collapse">
                <ul class="nav">
                    
            <li><a href="archive.html">Archives</a>
            </li><li><a href="categories/index.html">Tags</a>
            </li><li><a href="rss.xml">RSS</a>

                </li></ul>
                <ul class="nav pull-right">
                
                
                 
                </ul>
            </div>
        </div>
    </div>
</div>
<!-- End of Menubar -->
<div class="container-fluid" id="container-fluid">
    <!--Body content-->
    <div class="row-fluid">
    <div class="span2"></div>
    <div class="span8">
    
        <div class="postbox">
        <h1><a href="posts/201205contextlib2-04-now-with-exitstack.html">contextlib2 0.4: Now with ExitStack!</a>
        <small>  
             Posted: <time class="published" datetime="2012-05-05T15:06:00">2012-05-05 15:06</time>
        </small></h1>
        <hr>
        <p>Inspired by Michael Foord's efforts with <span>unittest2</span>, <a href="http://contextlib2.readthedocs.org/">contextlib2</a> is a PyPI package where I am working on some new additions to the standard library's <span>contextlib</span> module for Python 3.3.<br><br>The most interesting of those is a replacement for the ill-fated <a href="http://docs.python.org/library/contextlib#contextlib.nested">contextlib.nested</a> API.<br><br>If you use Python 3.2 today, you'll find that the <span>contextlib.nested</span> API doesn't even exist any more. The reason it was deprecated and removed is because it didn't play well with context managers that acquired their resources in <span>__init__</span> rather than <span>__enter__</span> (such as Python's own file objects and many other resources where using a with statement for management is an optional convenience rather than being mandatory).<br><br>The simplest example where the old API caused problems was opening a list of files and then using <span>contextlib.nested</span> to close them all when the operation was complete - if opening any later file threw an exception (e.g. due to a permissions error or a bad file name), then all of the earlier files would remain open until the garbage collector got around to cleaning them up. Not a huge problem on CPython with its refcounting based GC, but a far cry from the deterministic resource cleanup that context managers are supposed to offer.<br><br>Since the deprecation and removal of <span>contextlib.nested</span>, there have been assorted replacement proposals of varying levels of sophistication posted to the Python ideas mailing list. The new <a href="http://contextlib2.readthedocs.org/en/latest/index.html#contextlib2.ExitStack">ExitStack</a> API in this release is my own latest effort, and the first that I've liked well enough to seriously consider as a candidate for inclusion in the standard library module.<br><br>The idea behind providing the <span>ExitStack</span> API is for the standard library to focus specifically on handling the one particularly tricky part of dealing with context managers programmatically: unwinding the context stack correctly, ensuring that exceptions are processed exactly as if any context managers involved had been used in an appropriate series of nested with statements.<br><br>A couple of convenience methods are included (one that enters a context manager in addition to pushing the exit method on to the stack, as well as a simple callback registration method inspired by <span>unittest.TestCase.addCleanup</span>), but the features of the API are otherwise fairly minimal.<br><br>This low level dynamic API can then be used by developers to create their own higher level convenience APIs, as suggested in some of the <a href="http://contextlib2.readthedocs.org/en/latest/index.html#replacing-any-use-of-try-finally-and-flag-variables">examples</a> in the documentation.<br><br>A few specific design notes:<br></p><ul><li>The name <span>ExitStack</span> came about because the object is literally a stack of exit method references (or callback wrappers that behave like exit methods). Earlier variants were <span>ContextStack</span> (too narrow, since you can use the stack for standalone callbacks) and <span>CallbackStack</span> (too broad, since the stored callbacks specifically have the signature of exit methods)</li><li>The <span>push()</span> method accepts exit methods directly, since those are what actually gets stored on the stack. Ducktyping to also accept objects with an <span>__exit__()</span> method is convenient without being confusing (I hope).</li><li>The <span>enter_context()</span> method uses the longer name because the shorter version is too easy to confuse with the stack's own <span>__enter__()</span> method.</li></ul>If you have any questions about the <span>ExitStack</span> design, this is the place to ask. If you find any bugs or other defects, head over to the <a href="https://bitbucket.org/ncoghlan/contextlib2/issues?status=new&amp;status=open">issue tracker</a>.<br>
            
    <p>
        <a href="posts/201205contextlib2-04-now-with-exitstack.html#disqus_thread" data-disqus-identifier="cache/posts/201205contextlib2-04-now-with-exitstack.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201201walkdir-03-released-for-more-python.html">WalkDir 0.3 released (for more Python versions, thanks to Shining Panda!)</a>
        <small>  
             Posted: <time class="published" datetime="2012-01-31T12:44:00">2012-01-31 12:44</time>
        </small></h1>
        <hr>
        <a href="http://walkdir.readthedocs.org/">WalkDir</a> is my Python support library that aims to make it as easy to work with filtered directory listings as it is to walk over entire directory trees with os.walk().<br><br>The module's design tries to take full advantage of Python's iterator model - most of its functionality is provided by pipelined iterators that accept os.walk() style iterables and expose the same interface themselves. <br><br>The only major functional change in version 0.3 is that these pipelined iterators now make sure they pass along the objects produced by the underlying iterators, and only use indexing operations to access the individual fields. Previously they would use tuple unpacking to access the directory details, which restricted the supported types to those with exactly 3 fields and also had the side effect of replacing the underlying objects with ordinary 3-tuples.<br><br>I changed this mainly due to a new OS interface that is likely to be coming in Python 3.3: an <a href="http://bugs.python.org/issue13734">os.walk() variant</a> that produces a 4-tuple rather than a 3-tuple. The 4th value will be a file descriptor for the directory making it easier (in conjunction with new <a href="http://docs.python.org/dev/whatsnew/3.3.html#os">file descriptor based APIs</a> in the 3.3 os module) to write filesystem modification code that is robust against <a href="http://bugs.python.org/issue4489">symlink attacks</a>. By passing the underlying objects through unmodified, WalkDir is now compatible with this API - all the path based filtering will still work, but the file descriptor values will also be passed along correctly.<br><br>For those that haven't seen any of my previous comments on WalkDir, the other parts of the API are just there for convenience - one factory  function that constructs pipelines for you, and 3 terminal iterators  that flatten out the os.walk() style triples into a simple series of  paths (all paths, just the visited directories or just the file paths).<br><br>The other notable change in 0.3 is the list of officially supported versions. Previously, the module was only known to work on 2.7 and 3.2+ (since they're the versions I have on my home development machine). However, thanks to a free open source account provided by the folks at <a href="https://jenkins.shiningpanda.com/ncoghlan-devs-projects/job/WalkDir/">Shining Panda</a>, WalkDir 0.3 is known to work on Python 2.6, 2.7 and 3.1+ (I even test it on PyPy and Stackless, just because I can). After pushing a broken package to PyPI for 0.2, I even have a <a href="https://jenkins.shiningpanda.com/ncoghlan-devs-projects/job/WalkDirInstaller/">sanity check</a> I can run that ensures the module can be downloaded with pip and then imported on all the supported versions.<br><br>
            
    <p>
        <a href="posts/201201walkdir-03-released-for-more-python.html#disqus_thread" data-disqus-identifier="cache/posts/201201walkdir-03-released-for-more-python.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201201using-sopa-protests-to-highlight.html">Using the SOPA protests to highlight related problems in Australia</a>
        <small>  
             Posted: <time class="published" datetime="2012-01-18T09:47:00">2012-01-18 09:47</time>
        </small></h1>
        <hr>
        <p>I  figure this is the easiest place to publish the message I just sent to  Larissa Waters, the Greens Senator that is one of Queensland's  representatives in the Federal Senate. I also wrote to Yvette D'ath (our  local MHR) a few days ago, but I didn't keep a copy of that one. Will  this achieve anything? Probably not, but hey, at least I tried (and if  none of their constituents ever write to them about it, our reps are  quite entitled to assume we're all OK with them selling out the county  to legacy US media interests): <br></p><blockquote class="tr_bq"><i>Senator Waters,<br><br>With  today being the day Wikipedia and a wide range of other sites have  either gone dark or taken other action to protest draconian internet  censorship legislation making its way through the US Congress, it seems  an opportune time to highlight our own government's ongoing concerning  behaviour on that front.<br><br>Of particular concern is their <a href="http://delimiter.com.au/2012/01/17/govt-censors-secret-anti-piracy-meeting-notes/">continuing refusal</a> to release details of a secretive meeting between government  representatives and representatives of the same organisations that are  behind the draconian US bills currently being protested. The government  even <a href="http://delimiter.com.au/2011/12/23/secret-piracy-talks-govt-banned-consumer-groups/">deliberately excluded</a> representatives of a number of community interest organisations that sought to attend these discussions.<br><br>These  legacy media companies (aka horse drawn carriage manufacturers) are  flailing around wildly as the rise of free and open digital  communications networks (aka automobiles) threatens the cherished  gatekeeper role they have enjoyed for the past few decades as media  distributors. They have failed to adapt, and are increasingly being  bypassed as artists, writers, musicians, comedians and other media  creators find ways to use the power of the internet to connect more  directly with their fans. These direct connections are great for both  artists and fans, but place the intermediaries like YouTube, Apple  iTunes, Amazon, BandCamp, Flickr, etc, in the role of service providers  to the artists and fans rather than gatekeepers to widespread  distribution. Unfortunately, instead of going gracefully into that good  night, these organisations are investing inordinate sums of money  worldwide in lobbying for legislation that would make the permissive,  open practices of most of these new service providers a recipe for  prohibitively high legal liabilities, effectively making those practices  unsustainable and thus breaking the internet as we know it today.<br><br>Australia  already markedly shifted many intellectual monopoly policies to favour  the interests of US copyright holders at the expense of Australian  citizens when we signed the US-FTA some time ago. We have also  participated in the secretive process of drafting the  Anti-Counterfeiting Trade Agreement, which spends far more time  considering digital copyright infringement than it does actual  counterfeiting. The current negotiations over membership in the  Trans-Pacific Partnership agreement raise legitimate fears that  Australia's intellectual monopoly policy will be shifted even further  towards the draconian position of the United State Trade Representative,  even as those policies are being protested strongly within the US  itself.<br><br>In line with your <a href="http://greens.org.au/policies/human-rights-democracy/community-participation-in-government">published policy</a> on community participation in government, do the Greens plan to  publicly question the government over their apparent willingness to  place the interest of large US companies ahead of those of individual  Australian citizens?<br><br>Regards,<br>Nick.</i></blockquote><br>
            
    <p>
        <a href="posts/201201using-sopa-protests-to-highlight.html#disqus_thread" data-disqus-identifier="cache/posts/201201using-sopa-protests-to-highlight.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201112new-year-python-meme-december-2011.html">New Year Python Meme - December 2011</a>
        <small>  
             Posted: <time class="published" datetime="2011-12-22T13:15:00">2011-12-22 13:15</time>
        </small></h1>
        <hr>
        <div class="entry-body"><div><div class="item-body"><div>I'm normally a curmudgeon about this kind of thing, but I enjoyed reading some of the other posts in this series <a href="http://tarekziade.wordpress.com/2011/12/20/new-years-python-meme-2/" target="_blank">Tarek</a> kicked off, so I decided to make my own contribution.<br><br><b>1. What's the coolest Python application, framework or library you have discovered in 2011?</b> <br>The move to Red Hat marked my entry into the world of web development (previously I'd merely been in interested observer of that world, rather than a participant). By far my favourite discovery since making that change is <a href="http://django-rest-framework.org/">django-rest-framework</a> - with that, I can use my web browser to browse early iterations of my server's REST API directly, without needing to write custom clients to process the JSON data from APIs that are still in a state of flux.<br><br>As a service, <a href="http://readthedocs.org/">ReadTheDocs</a> has been an absolute revelation - between that, code hosting &amp; issue management sites like BitBucket and GitHub and of course PyPI itself, it's now possible for an open source project to have a quite respectable web presence without the developers needing to understand anything more than Sphinx, source control and the project they're working on.<br><br><b>2. What new programming technique did you learn in 2011?</b> <br>REST would be the big one. I'd had some general exposure to the concept in the past, but there's no substitute for sitting down and building it into a product when it comes to understanding a programming or API design technique.<br><br><b>3. What's the name of the open source project you contributed the most in 2011? What did you do?</b> <br>CPython, by far - kibbitzing on python-dev and python-ideas (and import-sig too these days), writing and reviewing several different PEPs, documentation updates, code reviews and patch applications, as well as working on my own things (including the still-in-progress integration work for the 'yield from' expression that's coming in 3.3).<br><br>I also recently started up 4 separate open source projects - 3 PyPI modules to hopefully address deficiencies I see in the current standard library offerings, plus the upstream open source project for my current development efforts at Red Hat:<br><ul><li><a href="http://contextlib2.readthedocs.org/">contextlib2</a> (ContextStack has some potential as a new building block)</li><li><a href="http://walkdir.readthedocs.org/">WalkDir</a> (the idea here is to be the "itertools for os.walk()")</li><li><a href="http://shell-command.readthedocs.org/">Shell Command</a> (let Python handle control flow, the shell actual commands)</li><li><a href="https://fedorahosted.org/pulpdist/">PulpDist</a> (Bringing a semblance of order to small-scale rsync mirror networks)</li></ul><br><b>4. What was the Python blog or website you read the most in 2011?</b>  <br><a href="http://planet.python.org/" target="_blank">Planet Python</a>.<br><br><b>5. What are the three top things you want to learn in 2012?</b> <br>From a work point of view, getting my RHCSA (Red Hat Certified System Administrator) is at the top of the list. Coming up to speed on AMQP (Advanced Message Queuing Protocol) is a close second. Finally, I want to fill in more of the gaps in my very sketchy knowledge of web UI development (i.e. HTML/CSS/Javascript).<br><br><b>6. What are the top software, app or lib you wish someone would write in 2012?</b> <br>I want to see the <a href="http://readthedocs.org/docs/ncoghlan_devs-python-notes/en/latest/pep_ideas/preview_namespace.html">__preview__ namespace</a> (in particular, the regex module) make it into Python 3.3. But that requires a volunteer to step up and write the PEP, write the code and generally champion the idea (if we have to wait for me to do it, there's no way it will happen before 3.4).<br><br>Want to do your own list? here's how: <br><ol><li>copy-paste the questions and answer to them in your blog</li><li>tweet it with the <a href="https://twitter.com/#%21/search/%232012pythonmeme" target="_blank">#2012pythonmeme</a> hashtag</li></ol></div></div></div></div>
            
    <p>
        <a href="posts/201112new-year-python-meme-december-2011.html#disqus_thread" data-disqus-identifier="cache/posts/201112new-year-python-meme-december-2011.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201112help-improve-python-33-standard-library.html">Help improve the Python 3.3 Standard Library...</a>
        <small>  
             Posted: <time class="published" datetime="2011-12-16T13:40:00">2011-12-16 13:40</time>
        </small></h1>
        <hr>
        <p>... and hopefully help yourself with current programming projects, too.<br><br>Some recent programming activities left me underwhelmed by a few of the standard library's included batteries. This has already led to a significant revamp of the <a href="http://docs.python.org/library/subprocess">subprocess module documentation</a> to steer new users away from the Popen Swiss army knife (unless they really need it) and to explain the commonly needed parameters more clearly. It still needs work (the notes and warnings are far too repetitive), but it at least introduces things in the right order now (high level convenience API that most people want first, lower level Popen API that some people need second).<br><br>However, for 3.3 I'd like to improve things even more in at least three areas: invocation of the system shell for administration tasks, better tools for traversing filesystem directories and programmatic management of deterministic resource cleanup (i.e. not relying on the garbage collector).<br><br>Accordingly, I have 3 projects up on PyPI (with docs on ReadTheDocs and source control and issue tracking on BitBucket):<br></p><ul><li><a href="http://walkdir.readthedocs.org/">WalkDir</a>: os.walk() style iterators with file and directory filtering (both inclusion and exclusion), depth limiting and symlink loop detection, as well as convenience iterators to flatten os.walk() style iterators into a series of paths (either all walked paths, just the directories or just the files). I currently plan to make (at least some of) these part of the shutil module, but exactly <i>what</i> gets added will be based on the feedback I receive on this module and its API design.</li><li><a href="http://shell-command.readthedocs.org/">Shell Command</a>: Convenience APIs that combine subprocess invocation with string interpolation. Interpolated strings are escaped with shlex.quote() by default, with a custom conversion specifier ("!u", for unquoted) used to invoke the standard interpolation process. It also features an experimental API where I'm tinkering with the use of select.select() on subprocess pipes (I'm not sure it achieves a lot over simple blocking IO in its current form, though). The current plan for this API is that it will be added directly to the subprocess module (well, the stable and sensible parts will be, anyway - I still have my doubts about the select.select() experiment)</li><li><a href="http://contextlib2.readthedocs.org/">contextlib2</a>: This module basically exists to let me publish and gather feedback on ContextStack, a proposed addition to contextlib for 3.3 that should make it easier to manage deterministic resource cleanup programmatically (i.e. without coupling it as directly to code layout as simple with statements do).</li></ul><br>Feedback on any and all of these is appreciated, either here or on the respective issue trackers. It isn't a foregone conclusion that any of these APIs will be added at all, so examples of real world use cases would definitely be helpful.
            
    <p>
        <a href="posts/201112help-improve-python-33-standard-library.html#disqus_thread" data-disqus-identifier="cache/posts/201112help-improve-python-33-standard-library.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201110correcting-ignorance-learning-bit-about.html">Correcting ignorance: learning a bit about Ruby blocks</a>
        <small>  
             Posted: <time class="published" datetime="2011-10-07T20:03:00">2011-10-07 20:03</time>
        </small></h1>
        <hr>
        <p>Gary Bernhardt pointed out at PyCodeConf that I didn't know Ruby even half as well as I should if I wanted to really understand why Ruby programmers rave about blocks so much (I started this before his talk, but it touches on his key point about the centrality of blocks to Ruby's design, and Python's lack of a similarly endemic model for code interleaving). So I set about trying to fix that (at least, to the extent I can in 24 hours or so). Unsurprisingly (since I'm not interested in becoming a Ruby programmer at this point in time), I approached this task more in terms of what it could teach me about Python (and its limitations) rather than in figuring out the full ins and outs of idiomatic Ruby. So feel free to bring it up in the comments if you think I've fundamentally mischaracterised some aspect of Ruby here.<br><br></p><h2>The first distinction: two kinds of function</h2>It turns out the first distinction shows up at quite a fundamental level. Ruby has two kinds of function: named methods and anonymous procedures. The semantics of these are quite different, most notably that named methods create their own local namespace, while anonymous procedures just use the namespace of the method that created them (so they're almost like ordinary local code).<br><br>Python also has two kinds of function: ordinary functions and generator functions. The name binding semantics are identical, but the invocation style and semantics are very different. Lambda expressions and generator expressions provide syntax for defining these inside an expression, but under the hood the semantics are still the same as those of the statement versions.<br><br>The closest you can get to a Ruby style anonymous procedure in Python is to create a named inner function and declare every otherwise local variable explicitly 'nonlocal' (in Python 3 - nonlocal declarations aren't available in Python 2). Then all name binding operations in the inner scope would also affect those names in the outer scope.<br><br><h2>Actually, make that three kinds of function</h2>The named method vs anonymous procedure distinction actually doesn't fully capture Ruby's semantics. Blocks (which is what I was most interested in learning about), add a new set of semantics that don't apply to the full object versions: they not only use the namespace of the defining method for their local variables, but their parameters are pass-by-reference (so they can rebind names in the calling namespace) and their control flow can affect the calling method (i.e. a return from a block will cause the calling method to return, not just the block itself). While somewhat interesting, I don't think these are actually all that significant - the core semantic difference is the one between Ruby's anonymous closures and Python's generators, not the dynamic binding behaviour of blocks.<br><br><h2>The implications: blocks versus coroutines</h2>This initial difference in the object model for code execution has created a fundamental difference in the way the two languages approach the problem of interleaving distinct pieces of code. The Ruby way is to define a separate piece of the current function that can be passed to other code and invoked as if it was still inline in its original location, then resuming execution when the called operation is complete. The Python way is to suspend execution, hand control back to the invoking piece of code, and then resume execution of the current code block at a later time (as determined by the invoking code).<br><br>Hence, where Ruby has specific syntactic sugar for passing a block of code to another method (do-end), Python instead has syntactic sugar for various invocation styles for coroutines (iteration via for loops, transactional code via with statements).<br><br>It's also the case that coroutines are not (yet) as deeply bound into Python's semantics as blocks are into Ruby. Whereas Ruby had blocks from the beginning and defined key programming constructs in terms of them (such as iteration and transactional style code via blocks), Python instead is built around various task specific protocols that may *optionally* be implemented in terms of coroutines (e.g. for loops, the iterator protocol and generators, the with statement, the context manager protocol and the contextlib.contextmanager decorator applied to a generator).<br><br><h2>Callback programming and hidden control flow</h2>One interesting outgrowth of the Ruby approach is that callback programming actually becomes a fairly natural extension of the way the language works - since programming with blocks <i>is</i> callback style programming, the invoking code doesn't really care if the called method runs the passed in block immediately or at some later time. Whether you consider this a good thing or a bad thing is going to depend on how you feel about the merits and dangers of hidden control flow.<br><br>During the discussions that led to the introduction of the with statement in Python 2.5, Guido made a clear, conscious design decision: he wanted the possible flows of control through the function body to be visible <i>locally</i> inside a function, without being dependent on the definitions of other methods (raising exceptions, of course, being an exception - <i>catching</i> them, though, largely obeys this guideline). Most code is run immediately, code in if statements and exception handlers is run zero or one times, code in loops is run zero or more times, code in nested function definitions is executed at some later time when the function is called. The Ruby blocks design is the antithesis of this: your control flow is entirely dependent on the methods you call. The downside of wanting visible control flow, of course, is that iteration, transactional code and callback programming all end up looking different at the point of invocation. (If you read PEP 340, Guido's original proposal for what eventually became the with statement, and contrast it with PEP 343, the version that we finally implemented, you'll see that his original idea was a fair bit closer to Ruby's blocks in power and scope).<br><br>So Ruby's flexibility comes at a price: when you pass a block to a method, you need to know what that method does in order to know how it affects your local control flow. Naming conventions can help reduce that complexity (such as the .each convention for iteration), but it does move control flow into the domain of programming conventions rather than the language definition.<br><br>On the other hand, Python's choice of explicit control flow comes at a price in flexibility: callback programming looks starkly different to ordinary programming as you have to construct explicit closures in order to pass chunks of code around.<br><br><h2>Two way data flow</h2>With their functional API, blocks natively supported two-way data flow from the beginning: data was passed in by calling them, and then either returned as the result of the block or by manipulating the passed in name bindings.<br><br>By contrast, Python's generators were originally output only, reflecting their target use case of iteration. You could input some initial data via parameters, but couldn't readily supply data to a running calculation. This has started to change in recent years, as generators now provide send() and throw() methods to pass data back in, and yield became an expression in order to provide access to the 'send()' argument. However, these features do not, at this stage, have deep syntactic support - there's a fairly obvious mapping from continue to send() and break to throw() that would tie them into the for loop syntax, but this capability has not garnered significant support when it has been brought up (I believe because it doesn't really help with the last major code execution model that Python doesn't provide nice native support for: callback programming).<br><br>In Python 3.3, generators will gain the ability to return values, and better syntax for invoking them and getting that value, moving the language even further towards full coroutine support (see PEP 380 for details). However, that is merely the next step along the path rather than arrival at the destination. <br><br><h2>Reinventing blocks</h2>I think the folks who accuse us of (slowly) reinventing blocks have a valid point - Python really is on the path of devising ways to handle tasks neatly with coroutines (i.e. functions that can be suspended and transparently resumed later without losing any internal state) that Ruby handles via blocks (i.e. extracting arbitrary fragments of a function body and passing them to other code). The fact that generators were <i>not</i> built into Python from the outset but instead have been added later to make certain kinds of code easier to write does show through in a variety of ways - coroutine based code often doesn't play nicely with ordinary imperative code and vice-versa.<br><br>Ruby's way has a definite elegance to it (despite the hidden control flow). I think aspiring to that kind of elegance for callback programming in Python would be a good thing, even if the semantic model is completely different (i.e. coroutine based rather than block based). The addition of actual block functionality remains unlikely, however - if they were as powerful as Ruby blocks, then it would create two ways to do too many things (with no obvious criteria to choose between the current technique and the block based technique), but if they were strictly less powerful, then reusing Ruby's block terminology would likely be confusing rather than enlightening. For better or for worse, Python is now well down the path of coroutine based programming and we likely need to see how far we can take that model rather than trying to shoehorn in yet another approach.
            
    <p>
        <a href="posts/201110correcting-ignorance-learning-bit-about.html#disqus_thread" data-disqus-identifier="cache/posts/201110correcting-ignorance-learning-bit-about.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201109spinning-up-pulpdist-project.html">Spinning up the pulpdist project</a>
        <small>  
             Posted: <time class="published" datetime="2011-09-27T16:23:00">2011-09-27 16:23</time>
        </small></h1>
        <hr>
        <p>One novel aspect of the <a href="http://www.boredomandlaziness.org/2011/09/mirror-all-things.html">pulpdist project</a> is that it is starting with an almost completely blank slate from a technology point of view (aside from the decision to use Pulp as the main component of the mirroring network). Red Hat does have development standards for internal projects, of course (especially in the messaging space), but they're fairly flexible, leaving the individual tool development teams with a lot of options. If something ships with Fedora and/or RHEL, or is available under licensing terms that would be acceptable for inclusion in Fedora (and subsequently RHEL), then it's fair game.<br><br>This post focuses on the design of the management server. I'll write up a separate post looking at the currently planned design for the Pulp data transfer plugins. <br><br></p><h2>Source Control</h2>Unsurprisingly, Red Hat's internal processes are heavily influenced by Linux kernel processes. Accordingly, the source control tool of choice for new projects is Git. While I have a slight preference for Mercurial (due mainly to familiarity), I'm happy enough with any DVCS, so Git it is.<br><br><h2>Primary Development Language</h2><a href="http://www.python.org/">Python</a>, of course. You don't hire a CPython core developer to get them to work on a Ruby or Perl project (although the current system I'm replacing was written in Perl). As a web application, there will naturally be some Javascript and CSS involved as well.<br><br><h2>Web Framework</h2>The main management application for pulpdist is going to be a full-scale web application. User profiles and authentication, database storage, communication with other web services, provision of a REST API, integration with the engineering tools messaging bus. Basically, micro-frameworks need not apply.<br><br>While I expect Pyramid/Pylons would also have been able to do the job, I decided to go with Django 1.3. This was heavily influenced by social factors: I know a lot of Django devs that I can bug for advice, but the same is not true for Pyramid. The complexity of the whole Pyramid/Pylons/TurboGears setup is also not appealing - while veteran web developers may find the "you decide" approach a selling point, Django's batteries included approach makes it far simpler to get started quickly, and decide as I go along which pieces I should keep, discard or replace.<br><br>I've heard some experienced Django developers muttering complaints about the class based views design in 1.3, but as someone coming in that is an experienced Python developer, but a relatively noobish web developer, the CBV approach seems eminently sensible, while the old function based approach looks repetitive and insane. Object oriented programming was invented for a reason!<br><br>I'll admit that my perception may be biased by knowing exactly how to make multiple inheritance work the way I want it to, though :)<br><br><h2>Web Server</h2>The management server doesn't actually have that much work to do, so the basic Apache+mod_wsgi configuration will serve as an adequate starting point (any heavy lifting will be done by the individual Pulp instances, and the main data traffic on those doesn't run through their web service). WSGI provides the flexibility to revisit this later if needed.<br><br>I've also punted on any web caching questions for now - the management server is low traffic and once the access to the Pulp sites is pushed out to a backend service, it should be fast enough at least for the early iterations. <br><br><h2>Authentication &amp; Authorisation</h2>The actual user authentication task will be handed off to Apache and all management application access will be restricted to Kerberos authenticated users over SSL. Django's own permissions systems will be used to handle authorisation restrictions. (The experimental prototype will use Basic Auth instead, since it is the Apache/Django integration the prototype needs to cover, not the Apache configuration for SSL and Kerberos authentication)<br><br>Integration with Pulp's user access controls is via OAuth, but the design for configuration of user permissions in the Pulp servers is still TBD.<br><br><h2>Database and ORM</h2>Again, the management server isn't doing the heavy lifting in this application. The Pulp instances use MongoDB, but for the management server I currently plan to use the standard Django ORM backed by PostgreSQL. For the prototype instance, the database is actually just an SQLite3 file. I'm not quite sold on this one as yet - it's tempting to start playing with SQLAlchemy, since I've already had to hack around some of the limitations in the native ORM in order to <a href="http://djangosnippets.org/snippets/2489/">store encrypted fields</a>. OTOH, I already have a ton of things to do on this project, so messing with this is a long way down the priority list.<br><br>Schema and data maintenance is handled using <a href="http://south.aeracode.org/">South</a>.<br><br><h2>HTML Templating</h2>The standard Django templating engine should be sufficient for my needs. As with the ORM, it's tempting to look into upgrading it to something like Jinja2, but once again 'good enough' is likely to be the deciding factor.<br><br>For data table display, I'm using <a href="http://pypi.python.org/pypi/django-tables2">Django Tables 2</a> and form display will use <a href="http://pypi.python.org/pypi/django-uni-form">Django Uni-Form</a>.<br><br><h2>REST API</h2>The REST API for the service is currently there primarily as a development aid - it lets me publish the full data model to the web as soon as it stabilises (and even while its still in flux), even if the UI for end users hasn't been fully defined. This is particularly useful for the metadata coming back from the Pulp server, since it doesn't need much post-processing to be included as raw data in the management server's own REST API. The JSON interface will also allow much of the backend processing to be fully exercised by the test suite without worrying about web UI details.<br><br>The design of the REST API was heavily influenced by this <a href="http://readthedocs.org/docs/restful-api-design/en/latest/">Lessons Learned</a> piece from the RHEV-M developers. The <a href="http://django-rest-framework.org/">Django Rest Framework</a> means I can just define the data I want to display as a list or dictionary and the framework takes care of formatting it nicely, including rendering URLs as hyperlinks. <br><br><h2>AMQP Messaging</h2>I haven't actually started on this aspect in any significant way, but the two main contenders I've identified are <a href="http://www.silassewell.com/blog/tag/python-qpid/">python-qpid</a> (which is what Pulp uses) and <a href="http://ask.github.com/django-celery/">django-celery</a> (which would also give me an internal task queue engine, which the management server is going to need - the prototype just does everything in the Django process, which is OK for experimentation on the LAN, but clearly inadequate long term when talking to multiple sites distributed around the planet). At this early stage, I expect the internal task management aspect is going to tip the decision in favour of the latter.<br><br><h2>Testing Regime<br></h2>As the foundation for the automated testing, I'm going with <a href="http://devel.almad.net/docs/django-sane-testing/">Django Sane Testing</a> (mainly based on the example of other internal Django projects). Michael Foord's <a href="http://pypi.python.org/pypi/mock">mock module</a> lets me run at least some of the tests without relying on an external Pulp instance (fortunately, the namespace conflict with Fedora's RPM building utility '<a href="https://fedoraproject.org/wiki/Projects/Mock">mock</a>' was recently resolved with the latter's support library being renamed to 'mockbuild').<br><br>Continuous integration is an open question at this point. Pulp uses Jenkins for CI and I'm inclined to follow their lead. The other main possibility is to use <a href="https://fedorahosted.org/beaker/">Beaker</a>, Red Hat's internal test system originally set up for kernel testing (one key attraction Beaker offers is the ability to set up multi-server multi-site testing in a test recipe so I can run tests over the internal WAN).<br><br><h2>Packaging<br></h2><a href="https://github.com/dgoodwin/tito">Tito</a> is a tool for generating SRPMs and RPMs directly from a Git repository. For my own packages, this is the approach I'm using (with handcrafted spec files). For some strange reason, the sysadmins around here like it when internal devs provide things as pre-packaged RPMs for deployment :)<br><br>Packaging of upstream PyPI dependencies that aren't available as Fedora or RHEL packages is still a work in progress. I experimented with Tito and git submodules (which doesn't work) and git subtrees (which does work, but is seriously ugly). My next attempt is likely to be based on <a href="http://pypi.python.org/pypi/py2pack">py2pack</a>, so we'll see how that goes (I actually discovered that project by searching for 'cpanspec pypi' after hearing some of the Perl folks here extolling the virtues of cpanspec for easily packaging CPAN modules as RPMs).<br><br>I also need to switch to using <a href="http://pypi.python.org/pypi/virtualenv">virtualenv</a> to get a clearer distinction between Fedora packages I added via yum install and stuff I picked up directly from PyPI with <a href="http://pypi.python.org/pypi/pip">pip</a>.<br><br><br>
            
    <p>
        <a href="posts/201109spinning-up-pulpdist-project.html#disqus_thread" data-disqus-identifier="cache/posts/201109spinning-up-pulpdist-project.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201109mirror-all-things.html">Mirror All The Things!</a>
        <small>  
             Posted: <time class="published" datetime="2011-09-09T02:54:00">2011-09-09 02:54</time>
        </small></h1>
        <hr>
        <p>After describing the project I'm working on to a few people at PyConAU and BrisPy, I decided it might be a good idea to blog about it here. I do have a bit of an ulterior motive in doing so, though - I hope people will point out when I've missed useful external resources or applications, or when something I'm planning to do doesn't make sense to the assorted Django developers I know. Yes, that's right - I'd like to make being <a href="https://www.xkcd.com/386/">wrong on the internet</a> work in my favour :)<br><br>The project is purely internal at this stage, but I hope to be able to publish it as open source somewhere down the line. Even being able to post these design concepts is pretty huge for me personally, though - before starting with Red Hat a few months ago, I spent the previous 12 and a half years working in the defence industry, which is about as far from Red Hat's <a href="http://draft.blogger.com/goog_2071189574">"</a><a href="http://draft.blogger.com/goog_2071189574">Default to Open" philosophy</a> as it's possible to get.<br><br></p><h2>  Mirror, Mirror, On The Wall</h2>The project Red Hat hired me to implement is the next generation of their internal mirroring system, which is used for various tasks, such as getting built versions of RHEL out to the hardware compatibility testing labs (and, when they're large enough, returning the generated log files to the relevant development sites), or providing internal Fedora mirrors at the larger Red Hat offices (such as the one here in Brisbane).<br><br>There are various use cases and constraints that mean the mirroring system needs to operate at the filesystem level without making significant assumptions about the contents of the trees being mirrored (due to various details of the use cases involved, block level replication and approaches that rely on the transferred data being laid out in specific ways aren't viable alternatives for this project). The current incarnation of this system relies almost entirely on that venerable workhorse of the mirroring world, <span>rsync</span>.<br><br>However, the current system is also showing its age and has a few limitations that make it fairly awkward to work with. Notably, there's no one place to go to get an overview of the entire internal mirroring setup, and the direct use of <span>rsync</span> means it isn't particularly friendly with other applications when it comes to sharing WAN bandwidth and the servers involved are wasting quite a few cycles recalculating the same deltas for multiple clients. Hence, the project I am working on, which is intended to replace the existing system with something a bit more efficient and easier to manage, while also providing a better platform for adding new features.<br><br><h2>  Enter Pulp</h2><a href="http://pulpproject.org/">Pulp</a> is an open source (Python) project created by Red Hat to make it easier to manage private <span>yum</span> repositories. Via <a href="http://katello.org/">Katello</a>, Pulp is one of the upstream components for Red Hat's <a href="https://www.redhat.com/solutions/cloud/cloudforms/">CloudForms</a> product.<br><br>The Pulp project is currently in the process of migrating from their original yum-specific architecture to a more general purpose <a href="http://blog.pulpproject.org/2011/09/06/pulp-rearchitecture-sprint-update/">Generic Content plugin architecture</a>. It's that planned plugin architecture that makes Pulp a useful basis for the next generation internal mirroring system, which, at least for now, I am imaginatively calling <span>pulpdist</span> (referring to both "distribution with Pulp", since that's what the system does, and "distributed Pulp instances", since that's how the system will work).<br><br>The main components of the initial <span>pulpdist</span> architecture will be:<br><ul><li>a front-end (Django 1.3) web app providing centralised management of the entire distribution network</li><li>custom importer and distributor plugins for Pulp to handle distribution of tree changes within the distribution network</li><li>custom importer plugins to handle the import of  trees from their original sources and generation of any additional metadata needed by the internal distribution plugins</li><li>generic (and custom, if needed) plugins to make the trees available to the applications that need them</li></ul><br>I'll be writing more on various details that I consider interesting as I go along. Initially, that will include my plan for the mirroring protocol to be used between the sites, as well as various decisions that need to be made when spinning up a Django project from scratch (while many of my specific answers are shaped by the target environment for internal deployment, the questions I needed to consider should be fairly widely applicable).
            
    <p>
        <a href="posts/201109mirror-all-things.html#disqus_thread" data-disqus-identifier="cache/posts/201109mirror-all-things.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201108open-source-windows-and-teaching-python.html">Open Source, Windows and Teaching Python to New Developers</a>
        <small>  
             Posted: <time class="published" datetime="2011-08-27T12:16:00">2011-08-27 12:16</time>
        </small></h1>
        <hr>
        <p>A few questions and incidents recently prompted me to reflect on why I don't help with CPython support on Windows, even though I use Windows happily enough on my gaming system. Since this ended up being a rather pro-Linux article and upfront disclosure is a good thing, I'll note that while I do work for Red Hat now, that's a very recent thing - my adoption of Linux as my preferred development platform dates back to 2004 or so. I work for Red Hat because I like Linux, not the other way around :)<br><br></p><h2>The Availability of Professional Development Tools</h2>I <a href="http://mail.python.org/pipermail/python-dev/2011-August/113111.html">don't make a secret</a> of my dislike of Windows as a hobbyist development platform. While Microsoft have improved things in recent years (primarily by releasing the Express editions of Visual Studio), there's still a huge difference between an operating system like GNU/Linux, which was built by developers for developers based on a foundation that was built by academics for academics, and Windows, which was built by a company that used deals with computer manufacturers to get it into end users' hands regardless of technical merit. Developers were forced to follow in order to reach that large installed user base. Those different histories are reflected in the different development cultures that surround the respective platforms.<br><br>To get the same tool chain that professional Linux companies use, you don't need to do anything special - Linux distributions include the tools used to create them. If you have a distribution, you have everything you need to build applications for that distribution, including documentation. With the open source nature of the platform and almost all of the software (the occasionally binary driver notwithstanding), there's a vast range of tools out there to help you get things done (although sorting through the mass can be a little tricky sometimes, since it can be hard to tell the difference between stuff that doesn't exist and stuff that exists, but hasn't been uncovered by your research).<br><br>As far as I'm aware, Mac OS X isn't quite as generous with freely available development utilities, but isn't all that far off the Linux approach (I'm not a Mac user or developer though, so there may be more hurdles than I am aware of - I recall some muttering about Apple beginning to charge a small fee for XCode. My opinion is based mostly on the fact that it seems pretty easy to find open source devs that use Macs). With the POSIX-ish underpinnings, many of the utilities from the *nix world also work in this environment.<br><br>The minimum realistic standard for professional Windows development, though, is an MSDN subscription (to get full access to the OS documentation and various utilities), along with a professional copy of Visual Studio. The tools available for free (including the Express editions of Visual Studio) are clearly second rate. Even when the tools themselves are OK, the licensing restrictions on the applications they create may make them practically useless (and MS have the gall to call the GPL viral - at least the gcc team don't restrict how you license and distribute the binaries it creates). So why should a hobbyist develop for a system that thinks they should pay substantial sums for the privilege of developing for it, instead of one that welcomes all contributors, providing not only the end product, but the ingredients and recipes all for free?<br><br>At the recent PyConAU sprints, one of the contributors (an existing Linux user that happened to have a Windows only laptop with them) became frustrated with getting all the necessary tools set up to work properly on Windows (configuring git+ssh for read/write access to a GitHub repo was one key point of irritation), and decided to dual boot Ubuntu on the machine instead. Twenty minutes later, she was up and running and hacking on the project she originally wanted to hack on. Granted, she already knew how to use Linux, but seriously, there's something fundamentally wrong with a platform when installing and dual-booting to a different OS is the easiest way to get a decent development environment up and running.<br><br>All that ends up putting cross-platform languages like Python in an interesting position: when developing with Python, you can often get away with <i>not</i> understanding the underlying details of your operating system, because the language runtime tries to provide a largely standardised interface on all platforms. However, many open source developers either don't use Windows at all, or genuinely dislike programming for it, so the burden of making things work properly on Windows falls on the shoulders of a comparatively small number of people, either those who genuinely like programming for the platform (yes, such people exist, I'm just not one of them), or those that are looking for any niche where they can usefully contribute and are happy enough to take on the task of improving Windows compatibility and support.<br><br>I don't have particularly hard numbers to back this up (other than the skew in core developer numbers vs overall OS popularity), but my intuition is that, at least for CPython, the user:core developer ratio is orders of magnitude higher for Windows than it is for Linux or Mac OS X.<br><br><h2>The Implications for Teaching Python on Windows</h2>Something cool that is going on at the moment is that a lot of folks are interested in the idea of teaching more people how to program with Python as the language used. However, the potential students (young and old) that they are wanting to teach often don't have any development experience at all and are using the most common consumer operating system (i.e. Windows). So good Windows support, and an easy installation experience are important considerations for these instructors. A request that is frequently made (with varying levels of respect and politeness), is that the official python.org Windows installer be updated to automatically adjust the PATH (or at least provide the option to do so), so that Python can be launched from the command line by typing "python" instead of something like "C:\Python27\python".<br><br>If educators want that <i>right now</i> their best bet is actually to direct their students towards the Windows versions of ActiveState's <a href="http://www.activestate.com/activepython/downloads">ActivePython Community Edition</a>. ActiveState add a few things to the standard installer, like PATH manipulation and additional packages (such as pywin32). They also bundle PyPM, which is a decent tool for getting PyPI packages on to Windows machines (at least, I've heard good things about it - I haven't actually used it myself). (That said, I believe I may need to caveat that recommendation a bit: as near as I can tell from their website, PyPM has been deliberately disabled for their 64-bit Windows Community Edition installer. Still, even in that case, you can easily grab additional packages direct from PyPI via "pip install" on the command line)<br><br>Brian Curtin is working on adding optional PATH manipulation to the python.org installer for 3.3, and there's a chance such a change might be backported to the next maintenance releases for 3.2 and 2.7 (no promises, though). Even if it does make it in, it will still be a while before the change is part of a binary release (especially given that Brian has only just started tinkering with it).<br><br>This is clearly a nice thing for beginners, especially those that aren't in the habit of tinkering with their OS settings, but I do honestly wonder how much of a difference it will make in the long run. In many ways, software development is one long exercise in frustration. You decide you want to fix bug X. But it turns out bug X is really due to bug Y. You could work around Y just to fix X, but the bigger bug would still be there. But then you discover that fixing bug Y properly requires feature Z, which doesn't exist yet, so a workaround (even an ugly one) starts to sound pretty attractive. "Yak shaving" (the highly technical term for things that you're working on solely because they're a prerequisite for what you actually <i>want</i> to be working on) is so common it's almost the norm rather than the exception. The many and varied frustrations of trying to use Windows as a hobbyist open source developer also won't magically go away just because the python.org installer starts automating one environment variable update - as soon as people are introduced to sites like GitHub and BitBucket, they'll get to discover the joy that is SSH and source control on Windows. If they get past that hurdle, they'll likely start to encounter the multitude open source projects that don't even <i>offer</i> Windows installers (if the project supports Windows at all), because their Windows developer count stands at a grand total of zero.<br><br><h2>Final Thoughts</h2>I hope the people teaching Python to beginners on Windows and the folks working on improving Windows support don't take this article as an attack on their efforts. I find both goals to be quite admirable, and wish those involved all the success they can find. But there are reasons I abandoned Windows as a personal development platform ~7 years ago and taught myself to use Linux instead. As far as I can tell, most of those reasons remain valid today, even after Microsoft started releasing the Express versions of Visual Studio in an attempt to stem the flood of hobbyist developers jumping ship.<br><br>The <a href="http://www.boredomandlaziness.org/2011/08/of-python-and-road-maps-or-lack-thereof.html">other day</a> I called the relative lack of Windows developers in open source a vicious cycle and I stand by that. If someone can learn to program, mastering Linux is going to be comparatively easy. For anyone seriously interested in open source development, using Linux (even in a virtual machine, the way I do on my gaming laptop) is by far the path of least resistance. Getting more Windows developers in open source requires that people care sufficiently about Windows as a platform that they don't just switch to Linux, but care about open source enough to start contributing at all, and that seems to be a genuinely rare combination.
            
    <p>
        <a href="posts/201108open-source-windows-and-teaching-python.html#disqus_thread" data-disqus-identifier="cache/posts/201108open-source-windows-and-teaching-python.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201108scripting-languages-and-suitable.html">Scripting languages and suitable complexity</a>
        <small>  
             Posted: <time class="published" datetime="2011-08-24T12:37:00">2011-08-24 12:37</time>
        </small></h1>
        <hr>
        <p>Steven Lott is a Python developer and blogger that I first came across via his prolific contributions to answering questions on Stack Overflow, and then later by reading his blog posts that appeared on Planet Python. His <a href="http://homepage.mac.com/s_lott/books/python.html">Building Skills in Python</a> book is a resource I've recently started suggesting newcomers to Python take a look at to see if his style works for them.<br><br>Some time ago, he posted about what he called the <a href="http://slott-softwarearchitect.blogspot.com/2011/05/curse-of-procedural-design.html">"Curse of Procedural Design"</a>: the fact that, beyond a certain point, purely procedural code typically starts drowning in complexity and becomes an unmaintainable mess. Based on that, he then started questioning whether or not he was doing the right thing by teaching the procedural aspects of Python first and leaving the introduction of object oriented concepts until later in the book.<br><br>Personally, I think starting with procedural programming is still the right thing to do. However, one of the key points of object-oriented design is that purely procedural programming <i>doesn't scale well</i>. Even in a purely procedural language, large programs almost always define essential data structures, and functions that work on those data structures, effectively writing object oriented code by convention. Object support built into the language makes this <i>easier</i> but it isn't essential (as large C projects like the Linux kernel and CPython itself demonstrate).<br><br>Where languages like Java can be an issue as beginner languages is that by <i>requiring</i> that all code be compiled in advance and written in an object oriented style, they set a minimum level of complexity for all programs written in that language. Understanding even the most trivial program in Java requires that you grasp the concepts of a module, a class, an instance, a method and an expression. Using a compiled procedural language instead at least lets you simplify that a bit, as you only need to understand modules, functions and expressions.<br><br>But the scripting languages? By means of a read-eval-print loop in an interactive interpreter, they let you do things in the right order, starting with the minimum level of complexity possible: a single expression.<br><br>For convenience, you may then introduce the concept of a 'script' early, but with an appropriate editor, scripts may be run directly in the application (giving an experience very similar to a REPL prompt) rather than worrying about command line invocation.<br><br>More sophisticated algorithms can then be introduced by discussing conditional execution and repetition (if statements and loops), but still without any need to make a distinction between "definition time" and "execution time".<br><br>Then, once the concept of algorithms has been covered, we can start to modularise blocks of execution as functions and introduce the idea that algorithms can be stored for use in multiple places so that "definition time" and "execution time" may be separated.<br><br>Then we start to modularise data and the associated operations on that data as classes, and explore the ways that instances allow the same operations to readily be performed on different data sets.<br><br>Then we start to modularise collections of classes (and potentially data and standalone functions) as separate modules (and, in the case of Python, this can be a good time to introduce the idea of "compilation time" as separate from both "definition time" and "execution time").<br><br>Continuing up the complexity scale, modules may then be bundled into packages, and packages into frameworks and applications (introducing "build time" and "installation time" as two new potentially important phases in program execution).<br><br>A key part of the art of software design is learning how to choose an appropriate level of complexity for the problem at hand - when a problem calls for a simple script, throwing an entire custom application at it would be overkill. On the other hand, trying to write complex applications using only scripts and no higher level constructs will typically lead to an unmaintainable mess.<br><br>In my opinion, the primary reason that scripting languages are easier to learn for many people is that they permit you to start immediately with code that "does things", allowing the introduction of the "function" and "class" abstractions to be deferred until later.<br><br>Starting with C and Java, on the other hand, always requires instructors to say "Oh, don't worry about that boilerplate, you'll learn what it means later" before starting in with the explanation of what can go inside a main() function or method. The "compilation time" vs "execution time" distinction also has to be introduced immediately, rather than being deferred until some later point in the material. There's also the fact that such languages are actually usually at least two languages in one: the top level "compile time" language that you use to define your data structures, functions and modules and the "run time" language that you actually use <i>inside</i> functions and methods to get work done. Scripting languages don't generally have that distinction - the top level language is the same as the language used inside functions (in fact, that's my main criteria for whether or not I consider a language to be a scripting language in the first place).</p>
            
    <p>
        <a href="posts/201108scripting-languages-and-suitable.html#disqus_thread" data-disqus-identifier="cache/posts/201108scripting-languages-and-suitable.html">Comments</a>

        </p></div>
    
<div>
<ul class="pager">
    <li class="previous">
        <a href="index.html">← Newer posts</a>
    </li><li class="next">
        <a href="index-2.html">Older posts →</a>
</li></ul>
</div>

    
       <script type="text/javascript">var disqus_shortname="boredomandlaziness";(function(){var a=document.createElement("script");a.async=true;a.type="text/javascript";a.src="http://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("HEAD")[0]||document.getElementsByTagName("BODY")[0]).appendChild(a)}());</script>

    


    </div>
    </div>
    <!--End of body content-->
</div>
<div class="footerbox">
    Contents © 2013 <a href="mailto:ncoghlan@gmail.com">Nick Coghlan</a> - <a href="https://creativecommons.org/publicdomain/zero/1.0/">CC0</a>, republish as you wish. - Powered by <a href="http://nikola.ralsina.com.ar">Nikola</a>
</div>



            <script src="assets/js/jquery-1.7.2.min.js" type="text/javascript"></script>
            <script src="assets/js/bootstrap.min.js" type="text/javascript"></script>
        <script src="assets/js/jquery.colorbox-min.js" type="text/javascript"></script>


    <script type="text/javascript">jQuery("a.image-reference").colorbox({rel:"gal",maxWidth:"80%",maxHeight:"80%",scalePhotos:true});</script>
</body>
</html>