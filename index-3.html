<!DOCTYPE html><html lang="en">
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta charset="utf-8">
    <meta name="description" content="Efficiency (a virtue) is the child of laziness and greed (both vices), while
much of our economic activity is devoted to preventing boredom in the idle
time created by increases in efficiency. To be human is to be a strange
creature indeed :)
">
    <meta name="author" content="Nick Coghlan">
    <title>Curious Efficiency (old posts page 3) | Curious Efficiency</title>
    
            <link href="assets/css/bootstrap.min.css" rel="stylesheet" type="text/css">
            <link href="assets/css/bootstrap-responsive.min.css" rel="stylesheet" type="text/css">
        <link href="assets/css/rst.css" rel="stylesheet" type="text/css">
        <link href="assets/css/code.css" rel="stylesheet" type="text/css">
        <link href="assets/css/colorbox.css" rel="stylesheet" type="text/css">
        <link href="assets/css/theme.css" rel="stylesheet" type="text/css">
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js" type="text/javascript"></script>
    <![endif]-->
            <link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">

    
    
    
</head>
<body>
<!-- Menubar -->
<div class="navbar navbar-fixed-top">
    <div class="navbar-inner">
        <div class="container">

        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
        </a>

            <a class="brand" href=".">
            Curious Efficiency
            </a>
            <!-- Everything you want hidden at 940px or less, place within here -->
            <div class="nav-collapse collapse">
                <ul class="nav">
                    
            <li><a href="archive.html">Archives</a>
            </li><li><a href="categories/index.html">Tags</a>
            </li><li><a href="rss.xml">RSS</a>

                </li></ul>
                <ul class="nav pull-right">
                
                
                 
                </ul>
            </div>
        </div>
    </div>
</div>
<!-- End of Menubar -->
<div class="container-fluid" id="container-fluid">
    <!--Body content-->
    <div class="row-fluid">
    <div class="span2"></div>
    <div class="span8">
    
        <div class="postbox">
        <h1><a href="posts/201103queenslands-unelected-leader-of.html">Queensland's "unelected" leader of the opposition</a>
        <small>  
             Posted: <time class="published" datetime="2011-03-29T11:47:00">2011-03-29 11:47</time>
        </small></h1>
        <hr>
        <p>Following the declaration of Brisbane's Lord Mayor that he is running for state parliament at the next election, and will be the leader of the opposition for that campaign, there is a trope making the rounds that he is somehow "unelected".<br><br>Out of curiosity, I decided to see how his numbers in the Brisbane City Council elections in 2008 stacked up against Anna Bligh's numbers in the 2009 state election.<br><br>The internet being what it is, official sources for these numbers weren't too hard to dig up:<br>I found the <a href="http://www.brisbane.qld.gov.au/about-council/elections/previous-election-results/index.htm">Lord Mayoral</a> results on the Brisbane City Council site<br>I found the <a href="http://www.ecq.qld.gov.au/elections/state/state2009/results/district73.html">Electorate of South Brisbane</a> results on the Electoral Commission Qld site (with the preferences taken into account <a href="http://www.ecq.qld.gov.au/elections/state/state2009/results/summary.html#12">here</a>).<br><br>Results:<br>Campbell Newman received 335,076 first preference votes for Lord Mayor (60% of the total).<br>After distribution of preferences, he received a total of 339,320 votes (66% of the total).<br>It's probably worth noting that the second placed candidate received 29% of the first round votes, increasing to 34% after distribution of preferences, so Newman actually did receive the majority of the remaining preferences, there just weren't many to go around.<br><br>Anna Bligh received 12,243 first preference votes in her electorate of South Brisbane (48% of the total).<br>After distribution of preferences, she received a total of 14,697 votes (65% of the total).<br><br>So, our State Premier holds her position on the back of the support of her party and around 15k people living in or near South Brisbane.<br><br>The new leader of the opposition will hold that position on the back of the support of his party and around 340k people living in the City of Brisbane.<br><br>Since the current population of Qld is estimated at 4.5 million people, effectively 7.5% of the state voted for Newman to be Brisbane's Lord Mayor, while only 0.3% voted for Bligh to represent the seat of South Brisbane.<br><br>And people are calling <i>Newman</i> an unelected leader?<br><br>(Yes, I'm aware that the nature of parliamentary governments based on geographic representation means that most constituents don't get to vote directly for their parliamentary leaders. The only purpose of this post is to point out how <i>dumb</i> that makes the "unelected" gibe sound when it is aimed at the directly elected Lord Mayor of a city the size of Brisbane)</p>
            
    <p>
        <a href="posts/201103queenslands-unelected-leader-of.html#disqus_thread" data-disqus-identifier="cache/posts/201103queenslands-unelected-leader-of.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201103thoughts-and-impressions-following.html">Thoughts and Impressions following PyCon 2011</a>
        <small>  
             Posted: <time class="published" datetime="2011-03-19T20:20:00">2011-03-19 20:20</time>
        </small></h1>
        <hr>
        <p>I'm back home following my inaugural trip to PyCon, so it seems like a good time to record my impressions of the summits, conference and sprints.<br><br>I really enjoyed the whole experience - kudos to Van Lindbergh, Jesse Noller and the rest of the volunteer team for organising everything. I'm glad to see the "apprenticeship" setup for the conference leadership continuing, with Jesse (the deputy coordinator this year) stepping up to coordinate Santa Clara, with the future coordinator for Montreal assisting during those two years.<br><br>The personal connection side of things was brilliant. When it comes to the folks that were already on python-dev before I really started to follow it back in late 2003, I've been interacting and working with them online for 8+ years, and there are of course many others that have joined python-dev in the intervening time. I'd seen a few of them in photos and videos, and heard a few in videos and podcasts, but by and large, this was the first time I had been able to connect faces and voices to names on the screen. Very cool stuff, including getting to meet Raymond Hettinger (who accepted my first patches back in '04, among them the looks-insane-but-it-works string hack to speed up the 2.x decimal module) and of course Guido himself (who was the one who actually granted me commit rights, essentially for making sense while arguing with him about PEP 340/346/343).<br><br>Getting ready for Pycon was actually also the motivation behind restarting this blog and adding it to Planet Python, finally getting myself a Twitter account (<a href="http://twitter.com/ncoghlan_dev">@ncoghlan_dev</a>) and (after getting home) hooking my DISQUS profile up to that. They're all aspects of taking a bit more of an active part in the wider Python community after getting a taste of it at PyconAU last year (despite the fact that I have yet to make it to a BrisPy meeting... Wednesday night just isn't a good night for me these days).<br><br>From a more technical perspective, there were a few things that I found particularly interesting:<br><br>1. PyPy is definitely starting to make the transition from "experimental platform for research into dynamic language optimisation" to "let's use this to make production code go faster". This shows not only in their benchmark results, but also in their efforts to update their website to be more production-user friendly and the effort to get more major projects running on it at the sprints, including those that stress the boundaries of the distinction between the language definition and CPython implementation details (*cough*SQLAlchemy*cough*). One of those efforts actually revealed <a href="http://bugs.python.org/issue11477">a bug</a> in one of the dark corners of the CPython implementation (folks in Hanover F at the sprints may have heard me swearing about my various attempts at fixing that one...)<br><br>2. There is definite interest in supporting Python 3 in more modules and packages, as well as improving the available information out there regarding published packages. There's likely to be at least one after-the-fact PEP to better explain one of the major C API changes that bit some sprinters attempting to forward port zc.buildout (I think that was the affected package), there is collaboration developing amongst the Linux distros (and others) to get more existing packages on Python 3 (join the <a href="https://anonbadger.wordpress.com/2010/10/25/python3-porting-organization/">python-porting</a> list if that project interests you), there are a couple of <a href="http://py3ksupport.appspot.com/">new</a> <a href="http://getpython3.net/">sites</a> with improved information on the level of Python 3 support in various modules, and the team behind <a href="http://www.djangopackages.com">djangopackages</a> are working on providing the same service for the whole of PyPI (and, no doubt, Python 3 support will end up being one of the points of comparison).<br><br>3. With distutils2 entering the standard library as "packaging" in 3.3 (to reflect the scope creep in the mission of the package, as well as to avoid name conflicts with future backports of distutils2 post 3.3 release), it was fascinating listening to the sprinters discussing how to take their clean 3.3 code from the standard library and backport it (as distutils2) to run on 3.2, 3.1, 2.7, 2.6, 2.5 and 2.4 without cluttering the stdlib version with backwards compatibility cruft. If their results are a match for their goals, then their new 2to3 and 3to2 inspired tool may end up becoming the basis for a general purpose Python "backport" transformation technique that is able to iteratively downgrade Python code to support earlier versions, while still allowing the use of clean, idiomatic code in the latest version.<br><br>4. The understanding of how best to leverage the Mercurial transition is still evolving on python-dev. My personal opinion has now developed towards one where I hope we will start using more feature clones (rather than branches within the main repository), with the main cpython repository only being used to accept feature-complete (or near complete) contributions. We're actually pretty close to supporting that model now, it just needs a few tweaks to the way builds are pushed to the buildbots to get us the rest of the way to being able to trial code on the full buildbot fleet without having to push it into the main repository first.<br><br>5. Collaboration efforts between the 5 biggest Python implementations (CPython, PyPy, Jython, IronPython, Stackless) continue to evolve. The PSF announced $10k in direct funding to PyPy at the start of the conference proper, the <a href="http://www.python.org/download/">main python.org download page</a> now includes links to the sites of the other 4 major implementations, more contributors to the other projects were given CPython push rights to allow standard library fixes to be contributed upstream rather than maintained in downstream forks, there are plans in progress to create a collaborative "speed.python.org" modelled on the existing <a href="http://speed.pypy.org/">PyPy benchmark site</a> and Brett Cannon plans to revive the PEP about splitting the standard library out to a separate source control repository.<br><br>6. Brian Curtin has a <a href="http://blog.briancurtin.com/2011/03/16/pycon-2011-cpython-sprint-newcomers/">nice write-up</a> welcoming several newcomers that made their first submissions to the CPython bug tracker at the sprints. Brett's idea of improving test coverage as an introductory activity is a *great* idea, since such changes are relatively easy to get started with, relatively easy to review, low risk of breaking anything (except the buildbots) and involve actually writing code. I'll also note here that Eric Snow spent the sprints working on a more esoteric idea that came out of a python-ideas discussion: see what would be involved in providing a variant on exec() that allowed an actual function body to be executed in a designated namespace.<br><br>I was also surprised (and somewhat concerned) at the number of people that perceived python-dev as a hostile, unwelcoming place. On further reflection, I realised there was actually some merit to that point of view, but that's a topic for another post.</p>
            
    <p>
        <a href="posts/201103thoughts-and-impressions-following.html#disqus_thread" data-disqus-identifier="cache/posts/201103thoughts-and-impressions-following.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201103python-language-summit-highlights.html">Python Language Summit - Highlights</a>
        <small>  
             Posted: <time class="published" datetime="2011-03-11T12:39:00">2011-03-11 12:39</time>
        </small></h1>
        <hr>
        <p>The language summit covered a fair bit more ground than the VM summit did, so this post only covers the topics that I personally found particularly interesting. My <a href="http://www.boredomandlaziness.org/2011/03/python-language-summit-rough-notes.html">rough notes</a> at least mention everything that was discussed.<br><br><b>Moar Speed</b><br>The question of speed, optimisations and benchmarking came up again. A lot of this was just retreading the ground from the <a href="http://www.boredomandlaziness.org/2011/03/python-vm-summit-somewhat-coherent.html">VM summit</a> with a wider audience. One thing that did become clearer is that the near-term points of contact for the speed.python.org concept are Maciej Fijałkowski from the PyPy team for the technical issues and Jesse Noller on the PSF side for the hosting/organisational issues (although I expect Jesse would welcome offers of assistance if anyone else, particularly existing PSF members, wanted to step up and help coordinate things).<br><br><b>Communicating the collective opinions of python-dev</b><br>Where are we going, what are we doing? The main communications channels for python-dev have historically been PEPs (including release PEPs), the What's New document for each release and of course the mailing list itself. The python-dev summaries project has been tried a couple of times, but generally burned out the people involved.<br><br>Doug Hellman (PSF communications officer) would like to try a setup where there is an official python-dev technical blog where major discussions and decisions (including the outcomes of PEPs) can be presented in easier to swallow chunks, giving the gist of significant decisions and discussions, with references back to the source PEPs and mailing list threads.<br><br>It's an interesting idea, but, as Guido pointed out, will likely require *new* people to step forward to do it that are interested in the idea of helping to provide a window into the goings-on of python-dev (hopefully the more interesting parts, where we aren't just arguing about the colour of the current bikeshed du jour). From a personal point of view, I know I've only just really started using *this* blog to talk about my own perspective on Pythonic stuff. Something that may be practical is for the python.org technical blog to highlight blog posts where existing core devs are talking about new and upcoming stuff on their personal blogs.<br><br>Doug Hellman is the point of contact for anyone interested in following up on this.<br><br><b>Policy on use of accelerator modules</b><br>There are a few unwritten policies regarding the use of implementation-specific accelerator modules to speed up parts of the standard library (such as "always test both versions", "the accelerated version should be API compatible with the Python version", "the interpreter should still work if the accelerated version is missing").<br><br>Brett Cannon has volunteered to write these down in an official policy PEP. While CPython is likely the main offender here, it will be suggested that other implmentations follow the same policy for their own accelerator modules. Patches to bring CPython more inline with this policy, include providing pure Python alternative of existing C-only modules, are definitely of interest.<br><br><b>Compatibility warnings</b><br>With the rise in significance of alternate implementations, some grey areas in the language definition (such as the reliance on refcounting semantics, abuse of the ability to store non-string keys in CPython namespaces, storing objects that implement the descriptor protocol in classes without considering the consequences) are potential sources for confusion when they break on other versions (or potentially even in future versions of CPython.<br><br>ResourceWarning was added a while back to cover the refcounting issue, and uncovered a few bugs in CPython and its test suite. The proposal is to add CompatibilityWarning as a peer exception to ResourceWarning and use it for cases where people are relying on CPython implementation accidents that aren't officially supported by the language definition.<br><br>Nobody has stepped forward to write the PEP for this as yet, but it may make an interesting sprint topic (I know at least Brett and I are around for the sprints, and there should be a few other CPython core devs kicking around).<br><br><b>Better exception info</b><br>ImportWarning will likely acquire a "module" attribute during the sprints (this is an easy one, since it will just reference the module's name). There are other expections that could probably do with having the repr() of critical bits of information stored separately on the exception object (e.g. KeyError, ValueError, IndexError) for easy programmatic access.<br><br>Using repr() helps avoid issues with reference cycles keeping things along longer than intended. However, the API for creating such enhanced exceptions would still need to be worked out, as well as how best to deal with cases where third party code has only populated the exception message without filling in the specific details. Technically, even ImportError isn't immune to that concern, as raising it is sometimes the responsibility of third party PEP 302 importers and loaders.</p>
            
    <p>
        <a href="posts/201103python-language-summit-highlights.html#disqus_thread" data-disqus-identifier="cache/posts/201103python-language-summit-highlights.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201103python-language-summit-rough-notes.html">Python Language Summit - Rough Notes</a>
        <small>  
             Posted: <time class="published" datetime="2011-03-10T22:31:00">2011-03-10 22:31</time>
        </small></h1>
        <hr>
        <p>Same drill, different day, more people, more notes :)<br><br>Still just my interpetation, though. Will probably highlight a few things I find particularly interesting again tomorrow (as I did for the VM summit).<br><br>PSF Communications (Doug Hellman)<br>- currently writing about PSF funding and similar activities<br>- would like to include more technical material summarising python-dev discussions<br>- how best to go about that<br>- new blog, not existing PSF blog<br>- existing PSF board not in the position to do it<br>- Guido: core devs already do a lot via PEPs and mailing list, likely not keen to write blog as well<br>- may be better to get others to do it, willing to follow discussions of interest<br>- posts may be primarily pointers to other resources (e.g. PEPs, mailing list posts)<br>- all implementations<br>- major new releases should go on python.org as NEWS items<br><br>Warnings for things that may cause problems on different implementations<br>- ResourceWarning helps to pick up reliance on CPython specific refcounting<br>- CompatibilityWarning for reliance on non-strings in namespaces (e.g. classes)<br>- update Language Spec to clarify ambiguous situations<br>- like ResourceWarning, silence CompatibilityWarning by default<br>- what to do about builtin functions that currently aren't descriptors (i.e. doesn't change behaviour when retrieved from a class)<br>- e.g. make staticmethod objects directly callable<br>- big gray area in language spec - callables may not be descriptors<br>- perhaps change CPython builtin descriptors to warn about this situation<br>- another use case for CompatibilityWarning<br>- Guido not convinced the builtin function problem can be handled in general<br>- a better callable variant of staticmethod may be better, that allows the default descriptor behaviour to be easily stripped from any function<br>- doesn't want to require that all builtin functions follow descriptor protocol, since it is already the case that many callables don't behave like methods<br>- a better staticmethod would allow the descriptor protocol to be stripped, ensuring such functions can be safely stored in classes without changing behaviour<br><br>Standard Library separation<br>- see VM summit notes<br>- over time, migrate over to separate repository for standard lib, update <br>- need Python and C modules stay in sync<br>- buildbots for standard library<br>- challenge of maintaining compatibility as standard lib adopts new language changes<br>- need a PEP to provide guarantees that C accelerators are kept in sync (Brett Cannon volunteered to write test)<br>- bringing back pure Python alternatives to C standard library is encouraged, but both need to be tested<br>- accelerator modules should be subsets of the Python API  <br>- Brett will resurrect standard library PEP once importlib is done<br>- full consolidation unlikely to be possible for 2.7 (due to CPython maintenance freeze)<br><br>Speed Benchmarking<br>- see VM summit notes<br>- really good for tracking performance changes across versions<br>- common set of benchmarks<br>- OSU OSL are willing to host it<br>- backend currently only compares two versions<br>- first step is to get up and running with Linux comparisons first, look at other OS comparisons later<br>- hypervisors mess with performance benchmarks, hence need real machines<br>- should set up some infrastructure on python.org (benchmark SIG mailing list, hg repository)<br>- eventually, redirect speed.pypy.org to new speed.python.org<br>- longer term, may add new benchmarks<br><br>Exception data<br>- need to eliminate need to parse error strings to get info from exceptions<br>- should be careful that checks of message content aren't overly restrictive<br>- PEP 3151 to improve IO error handling? (Guido still has some reservations)<br>- ImporError needs to name module<br>- KeyError, IndexError, ValueError?<br>- need to be careful when it comes to creating reference loops<br>- exception creation API also an issue, since structured data needs to be provided<br><br>Contributor Licensing Agreements<br>- Jesse and Van looking to get electronic CLAs set up<br>- will ensure adequately covers non-US jurisdictions<br><br>Google Summer of Code<br>- encouraging proposals under the PSF umbrella<br><br>Packaging<br>- distutils2 should land in 3.3 during the sprints<br>- namespace packages (PEP 382) will land in 3.3<br>- external name for backports should be different from internal name<br>- too late to introduce a standard top level parent for stdlib packages<br>- external backports for use in older versions is OK<br>- external maintenance is bad<br>- hence fast development cycles incompatible with stdlib<br>- want to give distutils2 a new name in stdlib for 3.3, so future backports based on version in 3.4 won't conflict with the standard version in 3.3<br><br>Python 3 adoption<br>- py3ksupport.appspot.com (Brett Cannon)<br>- supplements inadequate trope data on PyPI with manual additions<br>- Georg Brandl has graphical tracker of classification data on PyPI over time<br>- Allison Randall/Barry Warsaw have been doing similar dependency tracking and migration info for Ubuntu<br>- giant wiki page for Fedora Python app packaging<br>- good dependency info would provide a good ranking system for effectively targeting grants<br>- 3.python.org? getpython3.com? need to choose an official URL<br>- funding may help with PyPy migration<br>- IronPython will be looking at 3.x support once 2.7 is available (this week/next week timeframe)<br>- Jython focused on 2.6 now, may go direct to 3.x after that (haven't decided yet)<br>- PSF funding needs a specific proposal with specific developer resources with the necessary expertise and available time<br>- CObject-&gt;Capsule change is a compatibility issue for C extension modules<br>- Django targeting Python 3 support by the end of summer<br>- zc.buildout is a dependency of note that hasn't been ported yet (Pycon sprint topic)<br>- other migration projects being tackled at Pycon sprints (webop?)<br><br>Python upstream and distro packaging<br>- PEP 394 - recommendations for symlinks practices<br>- PEP 3147 and 3149 were heavily targeted at helping distros share directories across versions<br>- namespace packages (PEP 382)<br>- PEP 384 stable ABI (done for 3.2)<br>- better tools needed to help with migration to stable ABI<br><br>Baseline Python distro installs<br>- system python varies in terms of what is installed<br>- challenging to target, as available modules vary<br>- "build from source" is only a partial answer as some build dependencies are optional<br>- distros make some changes to support differences in directory layouts<br>- some changes affect Python app dependencies (e.g. leaving out distutils)<br>- conflict between "system Python" use case of what is needed to run distro utilities and "arbitrary app target" for running third party apps<br>- distributing separate Python under app control is not ideal, due to security patch management issues<br>- specific problems are caused by removal of stuff from base install (e.g. distutils)<br>- other problem is when distro uses old versions of packages (but virtualenv can help with that)<br>- may help if a "python-minimal" was used for the essential core, with "python" installing all the extras (including distutils, tkinter, etc)<br>- then have a further python-extras (or equivalent) that adds everything else the distro needs for its own purposes<br>- distros tend to work by taking a CPython build and then splitting it up into various distro packages<br>- to handle additions, would be good to be able to skip site-packages inclusion in sys.path (ala virtualenv).<br>- "-S" turns off too much (skips site.py entirely, not just adding site-packages to sys.path)<br>- "-s" only turns off user site-packages, not system site-packages<br><br>Python 3.3 proposed changes to strings to reduce typical memory usage<br>- PEP 393 changes to internal string representation (implementation as GSoC project)<br>- Unicode memory layout currently split in order to more easily support resizing and subclassing in C<br>- need to build and measure to see speed and memory impacts<br>- alternative idea may be to explore multiple implementation techniques (similar to PyPy)<br><br>Speed (again!)<br>- Unladen Swallow dormant. Major maintainers moved on to other things, fair bit of work in picking it up<br>- even trying to glean piecemeal upgrades (e.g. to cPickle) is a challenge<br>- interest in speeding up Python has really shifted to PyPy<br>- for CPython, gains would need to be really substantial to justify additional complexity<br>- really need to get the macro benchmarks available on 3.x<br>- Guido: pickle speedup experience is to be cautious, even when the speed gains are large. <br>- speed hack attempts on CPython are still of interest, especially educational ones<br>- speeding up overall is a very hard problem, but fixing specific bottlenecks is good<br>- stable ABI will help<br>- PyPy far more sensitive to refcounting bugs than CPython<br>- static analysis to pick up refcounting bugs could help a great deal<br>- "Here there be dragons": Unladen Swallow shows that overall speedups are not easy to come by<br><br>Regex engine upgrade<br>- new regex library proposed<br>- added many new features, including the Unicode categories needed to select out Python 3.x identifiers<br>- potentially big hassle for other implementations since re module includes a lot of C<br>- IronPython currently translates to .NET compatible regexes, but could rewrite more custom code<br><br>GUI Library<br>- Guido: GUI libraries are nearly as complicated as the rest of Python put together and just aren't a good fit with the release cycle of the standard lib<br>- Don't want to add another one, but don't want to remove Tcl/Tk support either<br><br>twisted.reactor/deferred style APIs in the standard library<br>- asyncore/aynchat still has users<br>- would like to have an alternative in the stdlib that offers a better migration path to Twisted<br>- deferred could be added, such that asyncore based apps can benefit from it<br>- reactor model separates transport/protocol concerns far more cleanly than asyncore<br>- protocol level API and transport level API for asyncore may be a better option<br>- would allow asyncore based applications to more easily migrate to other async loops<br>- defining in a PEP would allow this to be the "WSGI" for async frameworks ("asyncref", anyone?) (Jesse suggested concurrent.eventloop instead)<br>- still need someone to step up to write the PEP and integrate the feedback from the Twisted team and the other async frameworks<br>- plenty of async programming folks able to help and provide feedback (including glyph)<br>- having this standardised would help make event loop based programming more pluggable<br>- Guido still doesn't like the "deferred" name<br>- Glyph considers deferred to be less important than standardising the basic event loop interface</p>
            
    <p>
        <a href="posts/201103python-language-summit-rough-notes.html#disqus_thread" data-disqus-identifier="cache/posts/201103python-language-summit-rough-notes.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201103python-vm-summit-somewhat-coherent.html">Python VM Summit - Somewhat Coherent Thoughts</a>
        <small>  
             Posted: <time class="published" datetime="2011-03-10T12:38:00">2011-03-10 12:38</time>
        </small></h1>
        <hr>
        <p>Yay, sleep :)<br><br>Last night I just dumped my relatively <a href="http://www.boredomandlaziness.org/2011/03/python-vm-summit-rough-notes.html">raw notes</a> into a post. This review is more about distilling what was discussed over the day into a few key themes.<br><br><b>Speed Good</b><br><br>One major point was to do with "How do we make Python fast?". Dave Mandelin (Mozilla Javascript dev) was asking how open CPython was to people tinkering with JIT and other technologies to try and speed up execution, and it was acknowledged that python-dev's reaction to such proposals is rarely more than lukewarm. A large part of that resistance comes from the fact that CPython is generally portable to many more architectures than the real speed hacks (which are generally x86 + x86-64 + ARM at best, and sometimes not even all 3 of those). Unladen Swallow also lost a lot of steam, as so much of their effort was going into tasks not directly related to "make CPython faster" (e.g. fixing LLVM upstream bugs, getting benchmarks working on new versions).<br><br>Instead, we tend to push people more towards PyPy if they're really interested in that kind of thing. Armin decided years ago (when switching his efforts from psyco to PyPy) that "we can't get there from here", and it's hard to argue with him, especially given the recent results from the benchmarks executed by speed.pypy.org.<br><br>There was definitely interest in expanding the speed.pypy.org effort to cover more versions of more interpeters. We don't actually have any solid data in CPython regarding the performance differences between 2.x and 3.x (aside from an expectation that 3.x is slower for many workloads due to the loss of optimised 32 bit integers, additional encoding/decoding overhead when working with ASCII text, the new IO stack, etc). We aren't even sure of the performance changes within the 2.x series.<br><br>That last is the most amenable to resolution in the near term - the benchmarks run by speed.pypy.org are all 2.x applications, so the creation of a speed.python.org for the 2.x series could use the benchmarks as is. Covering 3.x as well would probably be possible with a subset of the benchmarks, but others would require a major porting effort (especially the ones that depend on twisted).<br><br>Champions and specific points of contact for this idea aren't particularly obvious at this stage. Jesse is definitely a fan of the idea, but has plenty on his plate already, so it isn't clear how that will work out from a time point of view. There'll likely need to be some self-organisation from folks that are both interested in the project and aren't already devoting their Python-relates energies to something else.<br><br><b>The Python Software Foundation, not the CPython Software Foundation</b><br><br>The second major key point was the PSF (as represented by Jesse Noller from the board, and several other PSF members, including me, from multiple VMs) wanting to do more to support and promote implementations other than CPython. We are definitely at the point where all 4 big implementations are an excellent choice depending on the target environment:<br><br></p><ul><li>CPython: the venerable granddaddy, compatible with the most C extensions and target environments, most amenable to "stripping" (i.e. cutting it down to a minimal core), likely the easiest sell in a corporate environment (due to age and historically closest ties to the PSF)</li><li>Jython: the obvious choice when using Python as a glue language for Java components, or as a scripting language embedded in a Java environment</li><li>IronPython: ditto for .NET components and applications</li><li>PyPy: now at the point where deployments on standard server and desktop environments should seriously consider it as an alternative to CPython. It's not really appropriate for embedded environments, but when sufficient resources are available to let it shine, it <i>will</i> run most workloads significantly faster than CPython. It even has some support for C extensions, although big ticket items like full NumPy support are still a work in progress. However, if you're talking something like a Django-based web app, then "CPython or PyPy" is now becoming a question that should be asked.</li></ul><br>It didn't actually come up yesterday, but Stackless probably deserves a prominent mention as well, given the benefits that folks such as CCP are able to glean from the microthreading architecture.<br><br>Currently, however, python.org is still very much the CPython website. It will require a lot of work it to get to a place where the other implementations are given appropriate recognition. It also isn't clear whether or not the existing pydotorg membership will go along with a plan to modernise the website design to something that employs more modern web technologies, and better provides information on the various Python implementation and the PSF. While the current site is better than what preceded it, a lot of pydotorg members are still gun shy due to the issues in managing that last transition (even the recent migration of the development process docs over to a developer-mainted system on docs.python.org encountered some resistance). However, when the broader Python community includes some of the best web developers on the planet, we can and <i>should</i> do better. (A personal suggestion that I didn't think of until this morning: perhaps a way forward on this would be to first build a new site as "beta.python.org", without making a firm commitment to switch until after the results are available for all to see. It's a pretty common way for organisations to experiment with major site revamps, after all, and would also give the pydotorg folks a chance to see what they think of the back-end architecture)<br><br><b>Standardising the Standard Library</b><br><br>Finally, with the hg transition now essentially done, efforts to better consolidate development effort on the standard library (especially the pure Python sections) and the associated documentation will start to gather steam again. As a preliminary step, commit rights (now more accurately called "push rights") to the main CPython repository are again being offered to maintainers from the other major interpreter implementations so they can push fixes upstream, rather than needing to maintain them as deltas in their own repositories and/or submit patches via the CPython tracker.
            
    <p>
        <a href="posts/201103python-vm-summit-somewhat-coherent.html#disqus_thread" data-disqus-identifier="cache/posts/201103python-vm-summit-somewhat-coherent.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201103python-vm-summit-rough-notes.html">Python VM Summit - Rough Notes</a>
        <small>  
             Posted: <time class="published" datetime="2011-03-10T01:28:00">2011-03-10 01:28</time>
        </small></h1>
        <hr>
        <p>In parallel with the the 2 days of tutorials at Pycon, there are a couple of day long meetings for invited folks active in the evolution of the language itself. Today was the VM summit, which focuses on the major Python interpreter implementations (CPython, PyPy, Jython, IronPython), the current status of each, and where things are likely to head in the near- and long-term. (The Thursday session focuses more on the evolution of the language itself, as well as of the wider ecosystem).<br><br>CPython and PyPy both had multiple devs at the summit, IronPython and Jython devs were also there (although IronPython got to share their's with CPython). We also has some Parrot VM folks there, as well as one of the Mozilla Javascript devs - a bunch of issues with VM development for dynamic languages apply across languages, despite differences in the surface syntax.<br><br>The notes below are probably too cryptic to make sense out of context, bit will hopefully give the gist of what was discussed. These notes are my interpretation of what was said, and may or may not reflect what people actually meant. Names omitted to protect the guilty (and because I didn't write them down)<br><br>Commit rights for other VM core devs<br>  - good idea<br>  - did some of this last Pycon US<br>  - will look into adding more this week<br><br>Splitting out the standard library and test suite (again)<br>  - duplication of effort between CPython/IronPython/Jython/PyPy<br>  - shared commit rights intended to make it easier near term to use CPython as master, allowing bugs to be fixed "upstream"<br>  - hg transition should make sharing easier<br>  - main CPython release will stay "batteries included"<br>  - open to the idea of providng "CPython minimal" and "standard library" downloads (but much work to be done in defining a minimum set)<br>  - longer term, may want to separate pure-Python stdlib development from "C skills required" hacking on the CPython interpreter core and C accelerated implementation modules for the stdlib<br><br>Speed benchmarking<br>  - speed.pypy.org (very cool!)<br>  - benchmarks originally chosen by Unladen Swallow team<br>  - PSF may talk to OSU OSL about setting up speed.python.org<br>  - benchmark multiple versions of CPython, as well as Jython and IronPython<br>  - currently benchmarks are 2.x specific, may be a while before 3.x can be compared fully<br>  - may be GSoC projects in:<br>      - improving backend infrastructure to handle more interpreters<br>      - porting benchmarks to Python 3<br>  - can highlight key performance differences between the implementations (e.g slowspitfire vs spitfire-cstringio)<br><br>Python.org download pages<br>  - should start recommending alternative interpreters more prominently<br>  - PyPy likely to be faster for pure Python on major platforms<br>  - IronPython/Jython/CPython still best at integration with their respective environments (Java libraries, .NET linraries, C extensions)<br><br>Cool hacks<br>  - Maciel: pypy JIT viewer<br>  - Dave Malcolm: CPython HEAP viewer in GDB 7<br>  <br>Parrot VM (and JIT for dynamic languages)<br>  - target VM for dynamic languages (primarily Perl 6 and Tcl at the moment)<br>  - loadable operations, loadable object types  <br>  - dynamic ops were original speed target, now moving towards dynamic types instead<br>  - exploring reducing number of core ops to make JIT more practical<br>  - looking into taking advantage of LLVM<br>  - Unladen Swallow blazed this trail, so LLVM has better dynamic language support<br>  - PyPy has tried and failed to use LLVM as an effective backend<br>  - some issues may have been fixed due to Unladen Swallow's efforts, but others still exist (e.g. problems with tail recursion)<br>  - SpiderMonkey similarly struggles with JIT and dynamic patching issues<br>  - GNU Lightning and LiveJIT projects noted, but nobody really familiar with them  <br>  - any future Python-on-Parrot efforts likely to focus on using PyPy frontend with Parrot as a backend<br>  - proof-of-concept written (for a thesis?) that used .NET as a backend target for PyPy<br>  - original Python-on-Parrot ran into problems due to semantic mismatches between Perl 6 and Python - reached the limits of the degree of difference the Perl 6 toolchain was willing to tolerate)<br>  <br>Role of the PSF<br>  - supports Python the Language, not just CPython the Reference Interpreter<br>  - could use additional feedback on how to better fulfill that role<br>  - getting the "boring stuff" done?<br>  - project-based grants, not blanket personal funding<br>  - project proposals requiring more funds than the PSF can provide are still valuable, as PSF can help facilitate co-sponsorships (however, still a novel concept - only been done once so far).<br><br>2.7 to 3.2<br>  - PyPy just reaching feature parity with 2.7<br>  - PyPy now becoming far more interesting for production usage<br>  - treat PyPy Python 3 dialect like a major Python library (e.g. sponsored by PSF)<br><br>CPython warnings for reliance on implementation details<br>  - ResourceWarning was a nice addition (detects reliance on refcounting for resource cleanup<br>  - non-string keys in class namespaces would be another good candidate for a warning<br>  - clarifying finalisation-at-shutdown semantics would be nice (but fixing those semantics in CPython first would help with that)</p>
            
    <p>
        <a href="posts/201103python-vm-summit-rough-notes.html#disqus_thread" data-disqus-identifier="cache/posts/201103python-vm-summit-rough-notes.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201103what-is-python-script.html">What is a Python script?</a>
        <small>  
             Posted: <time class="published" datetime="2011-03-06T14:19:00">2011-03-06 14:19</time>
        </small></h1>
        <hr>
        <p>This is an adaptation of a <a href="http://pyvideo.org/video/471/pyconau-2010--lightning-talks---saturday">lightning talk</a> I gave at PyconAU 2010, after realising a lot of the people there had no idea about the way CPython's concept of what could be executed had expanded over the years since version 2.4 was released. As of Python 2.7, there are actually 4 things that the reference interpreter will accept as a main module.<br><br><b>Ordinary scripts:</b> the classic main module identified by filesystem path, available for as long as Python has been around. Can be executed without naming the interpreter through the use of file associations (Windows) or shebang lines (pretty much everywhere else).<br><br><b>Module name:</b> By using the <span>-m</span> switch, a user can tell the interpreter to locate the main module based on its position in the module hierarchy rather than by its location on the filesystem. This has been supported for top level modules since Python 2.4, and for all modules since Python 2.5 (via PEP 338). Correctly handles explicit relative imports since Python 2.6 (via PEP 366 and the <span>__package__</span> attribute). The classic example of this usage is the practice of invoking <span>"python -m timeit 'snippet'"</span> when discussing the relative performance of various Python expressions and statements.<br><br><b>Valid sys.path entry:</b> If a valid sys.path entry (e.g. the name of a directory or a zipfile) is passed as the script argument, CPython will automatically insert that location at the beginning of <span>sys.path</span>, then use the module name execution mechanism to look for a <span>__main__</span> module with the updated <span>sys.path</span>. Supported since Python 2.6, this system allows quick and easy bundling of a script with its dependencies for internal distribution within a company or organisation (external distribution should still use proper packaging and installer development practices). When using zipfiles, you can even add a shebang line to the zip header or use a file association for a custom extension like <span>.pyz</span> and the interpreter will still process the file correctly.<br><br><b>Package name: </b>If a package name is passed as the value for the <span>-m</span> switch, the Python interpreter will reinterpret the command as referring to a <span>__main__</span> submodule within that package. This version of the feature was added in Python 2.7, after some users objected to the removal in Python 2.6 of the original (broken) code that incorrectly allowed a package's <span>__init__.py</span> to be executed as the main module. Starting in Python 3.2, CPython's own test suite supports this feature, allowing it to be executed as <span>"python -m test"</span>.<br><br>The above functionality is exposed via the <span>runpy</span> module, as <span>runpy.run_module() </span>and <span>runpy.run_path()</span>.<br><br>If anyone ever sees me (metaphorically) jumping up and down about making sure things get mentioned in the What's New document for a new Python version, this is why. Python 2.6 was released in October 2008, but we didn't get the note about the zipfile and directory execution trick into the What's New until February 2010. It is described in the documentation, but really, who reads the command line documentation, or is likely to be casually browsing the <span>runpy</span> docs? This post turning up on Planet Python will probably do more to get the word out about the functionality than anything we've done before now :)</p>
            
    <p>
        <a href="posts/201103what-is-python-script.html#disqus_thread" data-disqus-identifier="cache/posts/201103what-is-python-script.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201102status-quo-wins-stalemate.html">Status quo wins a stalemate</a>
        <small>  
             Posted: <time class="published" datetime="2011-02-27T15:07:00">2011-02-27 15:07</time>
        </small></h1>
        <hr>
        <p>Sometimes language design arguments can reach a point of stalemate. The status quo is only arguably flawed, and there are also perceived flaws in any or all of the proposed alternatives. An appropriate shared design principle can help identify when this point has been reached, and let the discussion die a natural death rather than endlessly rehashing the same points without anyone changing their opinion.<br><br>Every time we (python-dev) change anything significant, no matter how positive the end result, it can create a lot of churn in the community. Books need to be rewritten, other implementations modified, advice, recipes and examples updated, questions clarified as to which version they relate to, and version compatibility issues need to be monitored closely for projects that need to cope with older execution environments.<br><br>So, before any significant changes are made, we want to be fairly certain that the gain in clarity for future Python programs is worth the inevitable near term costs as the update ripples across the Python ecosystem. Sometimes newcomers have some interesting ideas, but still fail to clear this hurdle. The simple "it's not worth the hassle" response they're likely to receive may then come across as stodgy developers rejecting an outsider's ideas without adequate consideration.<br><br>This was something that came up fairly often during the Python 3000 mailing list discussions, to the point where I posted a message explaining why the principle of <a href="http://mail.python.org/pipermail/python-3000/2006-May/001936.html">"Status quo wins a stalemate"</a> is a very practical way to avoid meaningless churn in the language design and to cut short design discussions that obviously aren't going anywhere productive.<br><br>Python 3000 was already going to have a lot of major changes (most notably, finally improving the non-ASCII text handling story, in a way that means most Python 3 libraries and applications will be more likely to get it right). We needed to ride close herd on the design discussions to try to make sure that gratuitous changes with insufficient long term benefits were avoided.<br><br>So, lambda eventually stayed and map() and filter() were retained as builtins, while the attractive nuisance that is reduce() was merely banished to the functools module rather than getting dropped entirely as was originally proposed. PEP 348 was rejected to be replaced by the far less ambitious PEP 352. str.format() was still added, but as a complement to the legacy percent formatting mechanism rather than as a wholesale replacement.<br><br>Untold numbers of ideas on the mailing lists and the tracker were dropped with "too much pain for not enough benefit" as the rationale. More recently, PEP 3003 was instituted to enforce a moratorium on core language changes for Python 3.2 in order to give the rest of the community more time to catch up to Python 2.7 and the 3.x series, even though we knew it meant delaying good ideas like the improved generator refactoring capabilities provided by PEP 380.<br><br>The fact that Python 3 migration support tools like 2to3, 3to2 and the six module work as well as they do is probably due to this principle of language design as much as it is to any other factor (not to take anything away from the fine work that has gone into implementing them, of course!).</p>
            
    <p>
        <a href="posts/201102status-quo-wins-stalemate.html#disqus_thread" data-disqus-identifier="cache/posts/201102status-quo-wins-stalemate.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201102posting-code-and-syntax-highlighting.html">Posting code and syntax highlighting</a>
        <small>  
             Posted: <time class="published" datetime="2011-02-27T09:43:00">2011-02-27 09:43</time>
        </small></h1>
        <hr>
        <p>Before publishing the previous post, I looked into recommendations for syntax highlighting in coding-oriented blogs. In a quick search, syntaxhighlighter showed up repeatedly as the preferred choice, so that's what I went with.<br><br>It looks like I'm not the only one <a href="http://www.knowthytools.com/2010/03/blogging-with-restructuredtext-and.html">that isn't entirely happy with that solution</a> (although by using the "pre" tags rather than "script", my code should at least appear in the RSS feed).<br><br>Working with ReST would certainly be easier than the semi-HTML I'm currently using. Still, I think I have plenty to learn about Blogger's formatting tools before I abandon them entirely in favour of preformatted posts (which have their own drawbacks).</p>
            
    <p>
        <a href="posts/201102posting-code-and-syntax-highlighting.html#disqus_thread" data-disqus-identifier="cache/posts/201102posting-code-and-syntax-highlighting.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/201102justifying-python-language-changes.html">Justifying Python language changes</a>
        <small>  
             Posted: <time class="published" datetime="2011-02-27T09:13:00">2011-02-27 09:13</time>
        </small></h1>
        <hr>
        <p>A few years back, I <a href="http://mail.python.org/pipermail/python-dev/2008-October/082831.html">chipped in on python-dev</a> with a review of syntax change proposals that had made it into the language over the years. With Python 3.3 development starting and the language moratorium being lifted, I thought it would be a good time to tidy that up and republish it as a blog post.<br><br>Generally speaking, syntactic sugar (or new builtins) need to take a construct in idiomatic Python that is fairly obvious to an experienced Python user and make it obvious to even new users, or else take an idiom that is easy to get wrong when writing (or miss when reading) and make it trivial to use correctly.<br><br>Providing significant performance improvements (usually in the form of reduced memory usage or increased speed) also counts heavily in favour of new constructs.<br><br>I strongly suggest browsing through past PEPs (both accepted and rejected ones) before proposing syntax changes, but here are some examples of syntactic sugar proposals that were accepted.<br><br><b>List/set/dict comprehensions</b><br>(and the reduction builtins any(), all(), min(), max(), sum())<br></p><pre class="brush: py">target = [op(x) for x in source]</pre>instead of:<br><pre class="brush: py">target = []<br>for x in source:<br>    target.append(op(x))</pre>The transformation (`op(x)`) is far more prominent in the comprehension version, as is the fact that all the loop does is produce a new list. I include the various reduction builtins here, since they serve exactly the same purpose of taking an idiomatic looping construct and turning it into a single expression.<br><br><b>Generator expressions</b><br><pre class="brush: py">total = sum(x*x for x in source)</pre>instead of:<br><pre class="brush: py">def _g(source):<br>    for x in source:<br>        yield x*x<br>total = sum(_g(x))</pre>or:<br><pre class="brush: py">total = sum([x*x for x in source])</pre>Here, the GE version has obvious readability gains over the generator function version (as with comprehensions, it brings the operation being applied to each element front and centre instead of burying it in the middle of the code, as well as allowing reduction operations like sum() to retain their prominence), but doesn't actually improve readability significantly over the second LC-based version. The gain over the latter, of course, is that the GE based version needs a lot <i>less memory</i> than the LC version, and, as it consumes the source data<br>incrementally, can work on source iterators of arbitrary (even infinite) length, and can also cope with source iterators with large time gaps between items (e.g. reading from a socket) as each item will be returned as it becomes available (obviously, the latter two features aren't useful when used in conjunction with reduction operations like sum, but they can be helpful in other contexts).<br><br><b>With statements</b><br><pre class="brush: py">with lock:<br>    # perform synchronised operations</pre>instead of:<br><pre class="brush: py">lock.acquire()<br>try:<br>    # perform synchronised operations<br>finally:<br>    lock.release()</pre>This change was a gain for both readability and writability - there were plenty of ways to get this kind of code wrong (e.g. leave out the try-finally altogether, acquire the resource inside the try block instead of before it, call the wrong method or spell the variable name wrong when attempting to release the resource in the finally block), and it wasn't easy to audit because the resource acquisition and release could be separated by an arbitrary number of lines of code. By combining all of that into a single line of code at the beginning of the block, the with statement eliminated a lot of those issues, making the code much easier to write correctly in the first place, and also easier to audit for correctness later (just make sure the code is using the correct context manager for the task at hand).<br><br><b>Function decorators</b><br><pre class="brush: py">@classmethod<br>def f(cls):<br>    # Method body</pre>instead of:<br><pre class="brush: py">def f(cls):<br>    # Method body<br>f = classmethod(f)</pre>Easier to write (function name only written once instead of three times), and easier to read (decorator names up top with the function signature instead of buried after the function body). Some folks still dislike the use of the @ symbol, but compared to the drawbacks of the old approach, the dedicated function decorator syntax is a huge improvement.<br><br><b>Conditional expressions</b><br><pre class="brush: py">x = A if C else B</pre>instead of:<br><pre class="brush: py">x = C and A or B</pre>The addition of conditional expressions arguably wasn't a particularly big win for readability, but it <i>was</i> a big win for correctness. The and/or based workaround for the lack of a true conditional expression was not only hard to read if you weren't already familiar with the construct, but using it was also a potential source of bugs if A could ever be False while C was True (in such cases, B would be returned from the expression instead of A).<br><br><b>Except clause</b><br><pre class="brush: py">except Exception as ex:</pre>instead of:<br><pre class="brush: py">except Exception, ex:</pre>Another example of changing the syntax to reduce the potential for non-obvious bugs (in this case, except clauses like `except TypeError, AttributeError:`, that would actually never catch AttributeError, and would locally do AttributeError=TypeError if a TypeError was caught).
            
    <p>
        <a href="posts/201102justifying-python-language-changes.html#disqus_thread" data-disqus-identifier="cache/posts/201102justifying-python-language-changes.html">Comments</a>

        </p></div>
    
<div>
<ul class="pager">
    <li class="previous">
        <a href="index-2.html">← Newer posts</a>
    </li><li class="next">
        <a href="index-4.html">Older posts →</a>
</li></ul>
</div>

    
       <script type="text/javascript">var disqus_shortname="boredomandlaziness";(function(){var a=document.createElement("script");a.async=true;a.type="text/javascript";a.src="http://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("HEAD")[0]||document.getElementsByTagName("BODY")[0]).appendChild(a)}());</script>

    


    </div>
    </div>
    <!--End of body content-->
</div>
<div class="footerbox">
    Contents © 2013 <a href="mailto:ncoghlan@gmail.com">Nick Coghlan</a> - <a href="https://creativecommons.org/publicdomain/zero/1.0/">CC0</a>, republish as you wish. - Powered by <a href="http://nikola.ralsina.com.ar">Nikola</a>
</div>



            <script src="assets/js/jquery-1.7.2.min.js" type="text/javascript"></script>
            <script src="assets/js/bootstrap.min.js" type="text/javascript"></script>
        <script src="assets/js/jquery.colorbox-min.js" type="text/javascript"></script>


    <script type="text/javascript">jQuery("a.image-reference").colorbox({rel:"gal",maxWidth:"80%",maxHeight:"80%",scalePhotos:true});</script>
</body>
</html>